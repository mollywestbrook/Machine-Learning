{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load H5 file and print metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"model_comparison_6-13-2023.019_RaspiTestVid2_1000.analysis.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    dset_names = list(f.keys())\n",
    "    locations = f[\"tracks\"][:].T\n",
    "    node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "\n",
    "print(\"===filename===\")\n",
    "print(filename)\n",
    "print()\n",
    "\n",
    "print(\"===HDF5 datasets===\")\n",
    "print(dset_names)\n",
    "print()\n",
    "\n",
    "print(\"===locations data shape===\")\n",
    "print(locations.shape)\n",
    "print()\n",
    "\n",
    "print(\"===nodes===\")\n",
    "for i, name in enumerate(node_names):\n",
    "    print(f\"{i}: {name}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data by filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def fill_missing(Y, kind=\"linear\"):\n",
    "    \"\"\"Fills missing values independently along each dimension after the first.\"\"\"\n",
    "\n",
    "    # Store initial shape.\n",
    "    initial_shape = Y.shape\n",
    "\n",
    "    # Flatten after first dim.\n",
    "    Y = Y.reshape((initial_shape[0], -1))\n",
    "\n",
    "    # Interpolate along each slice.\n",
    "    for i in range(Y.shape[-1]):\n",
    "        y = Y[:, i]\n",
    "\n",
    "        # Build interpolant.\n",
    "        x = np.flatnonzero(~np.isnan(y))\n",
    "        f = interp1d(x, y[x], kind=kind, fill_value=np.nan, bounds_error=False)\n",
    "\n",
    "        # Fill missing\n",
    "        xq = np.flatnonzero(np.isnan(y))\n",
    "        y[xq] = f(xq)\n",
    "        \n",
    "        # Fill leading or trailing NaNs with the nearest non-NaN values\n",
    "        mask = np.isnan(y)\n",
    "        y[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), y[~mask])\n",
    "\n",
    "        # Save slice\n",
    "        Y[:, i] = y\n",
    "\n",
    "    # Restore to initial shape.\n",
    "    Y = Y.reshape(initial_shape)\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = fill_missing(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOSE_INDEX = 0\n",
    "LEYE_INDEX = 1\n",
    "REYE_INDEX = 2\n",
    "HEAD_INDEX = 3\n",
    "SPINE1_INDEX = 4\n",
    "SPINE2_INDEX = 5\n",
    "CAUDAL_INDEX = 6\n",
    "TAIL_INDEX = 7\n",
    "\n",
    "nose_loc = locations[:, NOSE_INDEX, :, :]\n",
    "Leye_loc = locations[:, LEYE_INDEX, :, :]\n",
    "Reye_loc = locations[:, REYE_INDEX, :, :]\n",
    "head_loc = locations[:, HEAD_INDEX, :, :]\n",
    "spine1_loc = locations[:, SPINE1_INDEX, :, :]\n",
    "spine2_loc = locations[:, SPINE2_INDEX, :, :]\n",
    "caudal_loc = locations[:, CAUDAL_INDEX, :, :]\n",
    "tail_loc = locations[:, TAIL_INDEX, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set('notebook', 'ticks', font_scale=1.2)\n",
    "mpl.rcParams['figure.figsize'] = [15,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize position data for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_data = [nose_loc, Leye_loc, Reye_loc, head_loc, spine1_loc, spine2_loc, tail_loc, caudal_loc]\n",
    "titles = ['Nose', 'Leye', 'Reye', 'Head', 'Spine1', 'Spine2', 'Tail', 'Caudal']\n",
    "colors = ['y', 'g', 'b', 'r', 'k']\n",
    "\n",
    "fig, axs = plt.subplots(4, 2, figsize=(20, 20))\n",
    "\n",
    "# Create an empty list to collect handles and labels from one subplot\n",
    "legend_handles = []\n",
    "legend_labels = []\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(2):\n",
    "        ax = axs[i, j]\n",
    "        ax.set_xlim(200, 1150)\n",
    "        ax.set_ylim(0, 1024)\n",
    "        ax.set_title(f'{titles[i * 2 + j]} tracks')\n",
    "\n",
    "        for k, color in enumerate(colors):\n",
    "            line, = ax.plot(tracking_data[i * 2 + j][:, 0, k], tracking_data[i * 2 + j][:, 1, k], color)\n",
    "            if i == 0 and j == 0:\n",
    "                # Collect handles and labels from the first subplot only\n",
    "                legend_handles.append(line)\n",
    "                legend_labels.append(f'Fish-{k + 1}')\n",
    "\n",
    "# Create a single legend with labels from the first subplot only\n",
    "fig.legend(legend_handles, legend_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing strategy to estimate tank boundaries for potential filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "points = np.vstack((tail_loc[:,0,0], tail_loc[:,1,0])).T\n",
    "\n",
    "hull = ConvexHull(points)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 3))\n",
    "\n",
    "for ax in (ax1, ax2):\n",
    "    ax.plot(points[:, 0], points[:, 1], color='k')\n",
    "    if ax == ax1:\n",
    "        ax.set_title('Given points')\n",
    "    else:\n",
    "        ax.set_title('Convex hull')\n",
    "        for simplex in hull.simplices:\n",
    "            ax.plot(points[simplex, 0], points[simplex, 1], 'c')\n",
    "        ax.plot(points[hull.vertices, 0], points[hull.vertices, 1], 'o', mec='r', color='none', lw=1, markersize=10)\n",
    "    ax.set_xticks(range(10))\n",
    "    ax.set_yticks(range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth data and differentiate to get velocity then visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def smooth_diff(node_loc, win=25, poly=3):\n",
    "    \"\"\"\n",
    "    node_loc is a [frames, 2] array\n",
    "    \n",
    "    win defines the window to smooth over\n",
    "    \n",
    "    poly defines the order of the polynomial\n",
    "    to fit with\n",
    "    \n",
    "    \"\"\"\n",
    "    node_loc_vel = np.zeros_like(node_loc)\n",
    "    \n",
    "    for c in range(node_loc.shape[-1]):\n",
    "        node_loc_vel[:, c] = savgol_filter(node_loc[:, c], win, poly, deriv=1)\n",
    "    \n",
    "    node_vel = np.linalg.norm(node_loc_vel,axis=1)\n",
    "\n",
    "    return node_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tracking data and the number of individuals\n",
    "tracking_data = [nose_loc, Leye_loc, Reye_loc, head_loc, spine1_loc, spine2_loc, caudal_loc, tail_loc]\n",
    "num_individuals = 5\n",
    "\n",
    "# Initialize a list to store the velocity data for each tracking point and individual\n",
    "velocity_data = []\n",
    "\n",
    "# Loop through each tracking point\n",
    "for data in tracking_data:\n",
    "    # Initialize a list to store the velocity data for each individual\n",
    "    point_velocity = []\n",
    "    \n",
    "    # Loop through each individual\n",
    "    for i in range(num_individuals):\n",
    "        # Calculate the velocity for the current individual and tracking point\n",
    "        vel = smooth_diff(data[:, :, i])\n",
    "        point_velocity.append(vel)\n",
    "    \n",
    "    velocity_data.append(point_velocity)\n",
    "\n",
    "    \n",
    "# velocity data is a nested list. To index: velocity_data[0][1] for nose and FISH-2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting velocity (heatmap)\n",
    "fig = plt.figure(figsize=(15,7))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(nose_loc[:, 0, 0], 'k', label='x')\n",
    "ax1.plot(-1*nose_loc[:, 1, 0], 'g', label='y')\n",
    "ax1.legend()\n",
    "ax1.set_xticks([])\n",
    "ax1.set_title('Nose Position')\n",
    "\n",
    "fishnnode = velocity_data[0][0]\n",
    "ax2 = fig.add_subplot(212, sharex=ax1)\n",
    "ax2.imshow(fishnnode[:,np.newaxis].T, aspect='auto', vmin=0, vmax=10)\n",
    "ax2.set_yticks([])\n",
    "ax2.set_title('Velocity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting velocity intensity by position\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(nose_loc[:, 0, 0], nose_loc[:, 1, 0], 'k')\n",
    "ax1.set_xlim(200,1150)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_ylim(0,1024)\n",
    "ax1.set_yticks([])\n",
    "ax1.set_title('Nose tracks (Fish1)')\n",
    "\n",
    "kp = velocity_data[0][0]  \n",
    "vmin = 0\n",
    "vmax = 10\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "scatter = ax2.scatter(nose_loc[:,0,0], nose_loc[:,1,0], c=kp, s=4, vmin=vmin, vmax=vmax)\n",
    "ax2.set_xlim(200,1150)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_ylim(0,1024)\n",
    "ax2.set_yticks([])\n",
    "ax2.set_title('Nose tracks colored by magnitude of swim speed (Fish1)')\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax2)\n",
    "cbar.set_label('Swim Speed')\n",
    "cbar.set_ticks(np.arange(0,10,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# velcity densities, could be useful for determining threshold??\n",
    "\n",
    "# nose velocity data \n",
    "nose_velocities = velocity_data[0][0]  \n",
    "\n",
    "# Create a histogram of nose velocities\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(nose_velocities, bins=20, density=True, alpha=0.6, color='b', label='Histogram')\n",
    "\n",
    "# Create a KDE plot of nose velocities\n",
    "sns.kdeplot(nose_velocities, color='r', label='KDE')\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel('Nose Velocity')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Nose Velocities')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Erroneous Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = nose_loc[:, 0, 3] \n",
    "y_data = nose_loc[:, 1, 3]\n",
    "# Set a threshold for the maximum allowable velocity\n",
    "velocity_threshold = 15 # Adjust this threshold as needed\n",
    "euclidean_distance_threshold = 10\n",
    "\n",
    "# Initialize a list to store potential error indices from velocity threshold and temporal consistency\n",
    "error_indices_velocity = []\n",
    "error_indices_TC = []\n",
    "# Initialize a list to store final tracking error indices \n",
    "error_indices_final = []\n",
    "\n",
    "# Find frames where the velocity exceeds the threshold\n",
    "error_indices_velocity = np.where(velocity_data[0][3] > velocity_threshold)[0]\n",
    "\n",
    "\n",
    "# Apply the temporal consistency approach by comparing Euclidean distances\n",
    "for i in range(1, len(x_data)):\n",
    "    if i > 0 and i < len(x_data) - 1:\n",
    "        # Calculate the Euclidean distance between the current frame and its neighboring frames\n",
    "        distance_prev = np.sqrt((x_data[i] - x_data[i - 1])**2 + (y_data[i] - y_data[i - 1])**2)\n",
    "        \n",
    "        \n",
    "        # Check if both neighboring frames exhibit consistency\n",
    "        if distance_prev > euclidean_distance_threshold:\n",
    "            error_indices_TC.append(i)\n",
    "\n",
    "# Create the final list of frames by finding frames that are in both lists\n",
    "error_indices_final = list(set(error_indices_velocity) & set(error_indices_TC))\n",
    "\n",
    "\n",
    "# Print the frames with potential tracking errors after applying temporal consistency by Euclidean distance\n",
    "if error_indices_final:\n",
    "    print(\"Potential tracking errors detected in frames:\", error_indices_final)\n",
    "else:\n",
    "    print(\"No tracking errors detected.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_data,y_data,c='b',s=70)\n",
    "plt.scatter(x_data[error_indices_final],y_data[error_indices_final],c='r',s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
